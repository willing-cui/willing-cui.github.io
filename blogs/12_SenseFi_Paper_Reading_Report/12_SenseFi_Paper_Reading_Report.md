# SenseFi：基于深度学习的WiFi人体感知库与基准测试详细报告

## 一、研究背景与意义

### 1.1 WiFi感知技术的发展现状

随着IEEE 802.11bf标准的制定，WiFi感知正式成为WiFi服务的组成部分。基于信道状态信息(CSI)的WiFi感知技术因其设备无关、隐私友好等优势，在人体活动识别、手势识别、人员计数等领域展现出巨大潜力。然而，与计算机视觉和自然语言处理领域相比，WiFi感知研究缺乏统一的基准测试平台。

### 1.2 SenseFi的创新价值

SenseFi作为首个面向WiFi感知的深度学习基准测试库，解决了以下关键问题：

- 模型性能评估缺乏统一标准
- 不同WiFi平台数据兼容性问题
- 学习策略有效性验证不足
- 实际部署中的效率权衡问题

## 二、技术框架与理论基础

### 2.1 CSI数据的基本原理

CSI记录了信号在多径传播环境中的详细特征。在OFDM-MIMO系统中，CSI表示为：

$$H_i=∣∣H_i∣∣e^{j∠Hi}$$

其中$H_i$和$∠H_i$分别代表第$i$个子载波的幅度和相位。

### 2.2 主流CSI工具对比

| 工具平台         | 子载波数量(20MHz) | 优势              | 局限性         |
| ---------------- | ----------------- | ----------------- | -------------- |
| Intel 5300 NIC   | 30                | 最早发布的CSI工具 | 分辨率较低     |
| Atheros CSI Tool | 56                | 高分辨率          | 平台依赖性较强 |
| Nexmon CSI Tool  | 256               | 智能手机兼容      | 数据噪声较大   |

### 2.3 CSI数据的多维特性

CSI数据包含三个关键维度：

- **空间维度**：子载波反映信号传播路径特征
- **时间维度**：时间序列描述环境动态变化
- **天线维度**：多天线提供信道多样性

## 三、SenseFi基准测试体系

### 3.1 数据集构建与特征

SenseFi整合了四个代表性数据集：

**UT-HAR数据集（不建议采用）**：

- 采集平台：Intel 5300 NIC
- 活动类别：7类基本活动
- 数据规模：约5000个样本，单一采集场景
- 特点：首个公开CSI数据集，但存在数据重叠问题，数据集规模小。

**Widar数据集**：

- 采集平台：Intel 5300 NIC
- 手势类别：22种精细手势
- 数据规模：43K样本，多环境采集
- 创新点：采用BVP（ body-coordinate velocity profile）特征消除环境依赖性

**NTU-Fi数据集**：

- 采集平台：Atheros CSI Tool
- 包含两个子集：HAR(6类活动)和Human-ID(14个被试)
- 特点：高分辨率(114子载波)，完美数据分割

**SenseFi基准测试的四个CSI数据集统计信息**

| 数据集     | UT-HAR[33]                               | Widar[34]                            | NTU-Fi HAR[36]                                     | NTU-Fi Human-ID[58]                |
| ---------- | ---------------------------------------- | ------------------------------------ | -------------------------------------------------- | ---------------------------------- |
| 平台       | Intel 5300 NIC                           | Intel 5300 NIC                       | Atheros CSI Tool                                   | Atheros CSI Tool                   |
| 类别数量   | 7                                        | 22                                   | 6                                                  | 14                                 |
| 类别名称   | 躺下、跌倒、行走、拾起、跑步、坐下、站起 | 推拉、扫地、拍手、滑动、18种绘图动作 | **拳击**、画圈、清洁、**跌倒**、**跑步**、**行走** | 14个被试的步态                     |
| 数据尺寸   | (3,30,250) (天线, 子载波, 数据包)        | (22,20,20) (时间,x速度,y速度)        | (3,114,500) (天线, 子载波, 数据包)                 | (3,114,500) (天线, 子载波, 数据包) |
| 训练样本数 | 3977                                     | 34926                                | 936                                                | 546                                |
| 测试样本数 | 996                                      | 8726                                 | 264                                                | 294                                |
| 训练周期   | 200                                      | 100                                  | 30                                                 | 30                                 |

### 3.2 深度学习模型架构详析

#### 3.2.1 基础模型原理

**多层感知机(MLP)**：

- 操作：将CSI数据展平为一维向量
- 公式：$Φ_i(z_i−1)=σ(W_iz_i−1)$
- 优势：参数丰富，拟合能力强
- 局限：破坏时空结构信息

**卷积神经网络(CNN)**：

- 卷积操作：$k⊗v=σ(k^Tv)$
- 类型：Conv1D(空间特征)和Conv2D(时空特征)
- 创新：注意力机制增强特征选择能力

**循环神经网络(RNN)**：

- 基本公式：$h_t=σ(W_xx_t+W_hh_{t−1})$
- 变体：LSTM/GRU解决长期依赖问题
- 应用：BiLSTM实现双向序列建模

#### 3.2.2 先进模型架构

**CNN-RNN混合模型**：

- 结构：CNN提取空间特征 + RNN建模时序依赖
- 代表：DeepSense框架的成功应用
- 优势：兼顾时空特征提取

**Transformer架构**：

- 自注意力机制：$\text{Attention}(Q,K,V)=softmax(\frac{Q\cdot K^T}{\sqrt{d_k}})⋅V$
- 特点：全局感受野，强表征能力
- 挑战：需要大量训练数据

## 四、实证研究与性能分析

### 4.1 监督学习性能对比

| Method    | UT-HAR  |           |            | Widar   |           |            | NTU-Fi HAR |           |            | NTU-Fi Human-ID |           |            |
| --------- | ------- | --------- | ---------- | ------- | --------- | ---------- | ---------- | --------- | ---------- | --------------- | --------- | ---------- |
|           | Acc (%) | Flops (M) | Params (M) | Acc (%) | Flops (M) | Params (M) | Acc (%)    | Flops (M) | Params (M) | Acc (%)         | Flops (M) | Params (M) |
| MLP       | 92.00   | 23.17     | 23.170     | 67.24   | 9.15      | 9.150      | **99.69**  | 175.24    | 175.240    | 93.91           | 175.24    | 175.240    |
| CNN-5     | 97.61   | 31.68     | 0.296      | 70.19   | 3.38      | 0.299      | 98.70      | 28.24     | 0.477      | 97.14           | 28.24     | 0.478      |
| ResNet18  | 98.11   | 49.93     | 11.180     | 71.70   | 38.39     | 11.250     | 95.31      | 54.19     | 11.180     | 96.42           | 54.19     | 11.190     |
| ResNet50  | 97.21   | 86.40     | 23.550     | 68.56   | 69.70     | 23.640     | **99.38**  | 90.66     | 23.550     | 92.91           | 90.67     | 23.570     |
| ResNet101 | 94.99   | 162.58    | 42.570     | 68.71   | 145.87    | 42.660     | 95.31      | 166.83    | 42.570     | 88.40           | 166.85    | 42.590     |
| RNN       | 83.53   | 2.51      | 0.010      | 47.05   | 0.66      | 0.031      | 84.64      | 13.09     | 0.027      | 89.30           | 13.09     | 0.027      |
| GRU       | 94.18   | 7.60      | 0.030      | 62.50   | 1.98      | 0.091      | 97.66      | 39.39     | 0.079      | 98.96           | 39.39     | 0.079      |
| LSTM      | 87.18   | 10.14     | 0.040      | 63.35   | 2.64      | 0.121      | 97.14      | 52.54     | 0.105      | 97.19           | 52.54     | 0.105      |
| BiLSTM    | 90.19   | 20.29     | 0.080      | 63.43   | 5.28      | 0.240      | **99.69**  | 105.09    | 0.209      | 99.38           | 105.09    | 0.210      |
| CNN + GRU | 96.72   | 39.99     | 1.430      | 63.19   | 3.34      | 0.092      | 93.75      | 48.38     | 0.058      | 87.48           | 48.39     | 0.058      |
| ViT       | 96.53   | 273.10    | 10.580     | 67.72   | 9.28      | 0.106      | 93.75      | 501.64    | 1.052      | 76.84           | 501.64    | 1.054      |

**Evaluation of deep neural networks (using supervised learning) on four datasets.**

### 4.2 迁移学习深度分析

#### 4.2.1 跨任务知识迁移

实验设置：从NTU-Fi HAR预训练到Human-ID微调

- 最佳迁移：CNN-5 (96.35%)
- 良好迁移：MLP (84.46%)、BiLSTM (80.20%)
- 迁移困难：RNN (57.84%)、CNN+GRU (51.73%)

#### 4.2.2 迁移学习有效性因素

1. **任务相似性**：HAR与Human-ID均涉及人体运动模式
2. **特征通用性**：CNN提取的空间特征具有更好的跨任务适应性
3. **过拟合风险**：复杂模型在源任务过拟合导致迁移性能下降

### 4.3 无监督学习突破性发现

#### 4.3.1 自监督学习框架

基于AutoFi的双网络架构：

- 并行编码器设计
- KL散度、互信息、核密度估计多目标优化
- 特征解耦与增强

#### 4.3.2 性能表现

- 最佳模型：CNN-5 (97.62%)
- 次优模型：MLP (89.12-90.48%)
- 显著优势：优于迁移学习效果，显示更好的特征泛化能力

### 4.4 训练动态与优化深入分析

#### 4.4.1 收敛特性比较

**收敛速度**：

- 快速收敛：CNN (25epoch内)、MLP
- 中等速度：Transformer、GRU
- 收敛困难：RNN (部分数据集难以收敛)

**训练稳定性**：

- 稳定训练：CNN、MLP
- 波动较大：GRU、LSTM (需仔细调参)

#### 4.4.2 优化器选择策略

**Adam优化器**：

- 优势：自适应学习率，快速收敛
- 问题：深层网络训练不稳定

**SGD优化器**：

- 优势：训练过程稳定
- 挑战：需要手动调整学习率和动量参数

#### 4.4.3 过拟合问题深度剖析

**ResNet在Widar上的过拟合**：

- 现象：训练准确率近100%，测试准确率低于20%
- 原因：跨域数据分布差异导致模型记忆特定模式
- 启示：复杂模型需要充分的跨域正则化

## 五、技术挑战与解决方案

### 5.1 数据效率提升策略

#### 5.1.1 少样本学习技术

- 原型网络：基于类原型的距离度量
- 对比学习：正负样本对优化特征空间
- 元学习：学习快速适应新任务的能力

#### 5.1.2 数据增强技术

- 时序变换：时间扭曲、缩放
- 空间增强：子载波丢弃、重排
- 多视角学习：天线间数据增强

### 5.2 模型效率优化

#### 5.2.1 轻量化设计原则

- 深度可分离卷积
- 通道注意力机制
- 神经架构搜索(NAS)

#### 5.2.2 模型压缩技术

- 知识蒸馏：教师-学生网络
- 网络剪枝：结构化剪枝策略
- 量化训练：低精度推理优化

### 5.3 多模态融合创新

#### 5.3.1 WiFi与视觉融合

- 特征级融合：中间层特征拼接
- 决策级融合：多模态投票机制
- 跨模态学习：WiFi到视觉的生成式学习

#### 5.3.2 跨模态监督

- Wi2Vi：CSI到视频帧的生成
- 姿态估计：基于OpenPose的监督信号
- 多任务学习：共享表征学习

## 六、实际部署建议

### 6.1 模型选择指南

基于实验结果的实用建议：

**精度优先场景**：

- 推荐：CNN-5、GRU、BiLSTM
- 考虑：模型集成提升稳定性
- 避免：过深的ResNet系列

**效率敏感场景**：

- 推荐：CNN-5、GRU
- 权衡：准确率与计算开销平衡
- 优化：模型量化与剪枝

### 6.2 训练策略优化

#### 6.2.1 学习策略选择

**监督学习**：

- 适用：充足标注数据场景
- 技巧：数据增强、标签平滑

**迁移学习**：

- 适用：相似任务间的知识迁移
- 关键：选择合适的预训练任务

**无监督学习**：

- 适用：标注数据稀缺场景
- 优势：学习更具泛化能力的特征

#### 6.2.2 超参数调优

- 学习率：自适应学习率调度
- 批大小：基于硬件内存的优化
- 正则化：Dropout、权重衰减策略

## 七、未来研究方向

### 7.1 技术前沿探索

#### 7.1.1 零样本学习

- 挑战：全新类别的识别能力
- 方法：属性学习、语义嵌入

#### 7.1.2 因果推理

- 目标：消除环境混淆因素
- 技术：因果表征学习

#### 7.1.3 联邦学习

- 应用：分布式隐私保护学习
- 挑战：非独立同分布数据优化

### 7.2 理论突破方向

#### 7.2.1 模型可解释性

- 目标：连接数据驱动与物理模型
- 方法：注意力可视化、特征归因

#### 7.2.2 统一理论框架

- 愿景：物理模型与学习模型的融合
- 基础：电磁传播理论与深度学习的结合

## 八、结论与展望

SenseFi通过系统性的基准测试，为WiFi感知研究提供了重要的实践指导。研究表明，适度复杂的深度学习模型（如CNN-5、GRU）在多数场景下表现优异，而过度复杂的模型可能因过拟合而性能下降。迁移学习和无监督学习为实际应用中的标注数据稀缺问题提供了有效解决方案。

未来随着IEEE 802.11bf标准的正式发布，WiFi感知将进入新的发展阶段。SenseFi作为开源基准测试库，将持续更新和完善，推动WiFi感知技术向更高效、更安全、更智能的方向发展。

**开源地址**：https://github.com/xyanchen/WiFi-CSI-Sensing-Benchmark

**NTU-Fi HAR 论文地址**：https://arxiv.org/pdf/2204.04138